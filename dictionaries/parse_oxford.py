#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä Oxford 3000 / 5000 –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ ‚Üí words.json
–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ = –æ–¥–Ω–∞ –∑–∞–ø–∏—Å—å

–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞:
[
  { "id": 1, "en": "the", "ru": "", "level": "A1" },
  { "id": 2, "en": "be", "ru": "", "level": "A1" },
  ...
]
"""

import json
import re
from pathlib import Path
import sys
from collections import defaultdict

# -------------------- –ù–ê–°–¢–†–û–ô–ö–ò --------------------

INPUT_FILES = {
    "A1": "A1 (3000).txt",
    "A2": "A2 (3000).txt",
    "B1": "B1 (3000).txt",
    "B2": "B2 (3000).txt",
    "B2_5000": "B2 (5000).txt",
    "C1": "C1 (5000).txt",
}

OUTPUT_FILE = "../words.json"

# –ü–æ—Ä—è–¥–æ–∫ —É—Ä–æ–≤–Ω–µ–π –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
LEVEL_ORDER = ["A1", "A2", "B1", "B2", "C1"]


# --------------------------------------------------

def extract_clean_word(line):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å—Ç–æ–µ —Å–ª–æ–≤–æ –∏–∑ —Å—Ç—Ä–æ–∫–∏
    –ü—Ä–∏–º–µ—Ä—ã:
    - "a, an indefinite article" ‚Üí "a"
    - "about prep., adv." ‚Üí "about"
    - "match (contest/correspond) n., v." ‚Üí "match"
    """
    # –£–±–∏—Ä–∞–µ–º –≤—Å—ë —á—Ç–æ –Ω–µ –±—É–∫–≤–∞ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
    match = re.match(r'^([a-zA-Z]+)', line)
    if match:
        return match.group(1).lower()

    # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
    first_part = line.split()[0] if ' ' in line else line
    clean = re.sub(r'[,\\.()]', '', first_part).lower()
    return clean


def parse_level_file(filepath: Path, level: str):
    """
    –ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –æ–¥–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
    """
    words = []
    seen = set()

    if not filepath.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
        return words

    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º—É—Å–æ—Ä
            if not line or "Oxford University Press" in line or line.startswith("¬©"):
                continue

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–æ
            word = extract_clean_word(line)
            if not word or word.isdigit() or word in seen:
                continue

            seen.add(word)
            words.append({
                "en": word,
                "ru": "",
                "level": level
            })

    return words


def deduplicate(words):
    """
    –£–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å
    """
    level_priority = {level: i for i, level in enumerate(LEVEL_ORDER)}
    unique = {}

    for w in words:
        word = w["en"]
        level = w["level"]

        if word not in unique:
            unique[word] = w
        elif level_priority[level] < level_priority[unique[word]["level"]]:
            unique[word] = w

    return list(unique.values())


def sort_words(words):
    """
    –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ —É—Ä–æ–≤–Ω—é, –∑–∞—Ç–µ–º –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
    """
    level_order = {level: i for i, level in enumerate(LEVEL_ORDER)}
    return sorted(words, key=lambda w: (level_order[w["level"]], w["en"]))


def print_stats(words):
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    """
    stats = defaultdict(int)
    for w in words:
        stats[w["level"]] += 1

    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print("-" * 25)
    total = 0
    for level in LEVEL_ORDER:
        count = stats.get(level, 0)
        total += count
        print(f"  {level}: {count:4d}")
    print("-" * 25)
    print(f"  –í—Å–µ–≥–æ: {total:4d}")


def main():
    print("üìö –ü–∞—Ä—Å–∏–Ω–≥ Oxford —Å–ª–æ–≤–∞—Ä–µ–π")
    print("=" * 40)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤
    for filename in INPUT_FILES.values():
        if not Path(filename).exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filename}")
            print("   –ó–∞–ø—É—Å–∫–∞–π—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–∑ –ø–∞–ø–∫–∏ dictionaries/")
            sys.exit(1)

    # –ü–∞—Ä—Å–∏–Ω–≥
    all_words = []
    for level_name, filename in INPUT_FILES.items():
        level = "B2" if level_name == "B2_5000" else level_name

        print(f"üìÑ {filename:<20} ... ", end="")
        words = parse_level_file(Path(filename), level)
        all_words.extend(words)
        print(f"{len(words):4d} —Å–ª–æ–≤")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    print(f"\nüîÅ –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ... ", end="")
    before = len(all_words)
    all_words = deduplicate(all_words)
    print(f"—É–¥–∞–ª–µ–Ω–æ {before - len(all_words)}")

    print(f"üîÄ –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ ... ", end="")
    all_words = sort_words(all_words)
    print("–≥–æ—Ç–æ–≤–æ")

    # –î–æ–±–∞–≤–ª—è–µ–º ID
    for i, word in enumerate(all_words, 1):
        word["id"] = i

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ {OUTPUT_FILE} ...")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write("[\n")
        for i, word in enumerate(all_words):
            # –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ = –æ–¥–Ω–∞ –∑–∞–ø–∏—Å—å
            line = f'  {{ "id": {word["id"]}, "en": "{word["en"]}", "ru": "{word["ru"]}", "level": "{word["level"]}" }}'
            if i < len(all_words) - 1:
                line += ","
            f.write(line + "\n")
        f.write("]\n")

    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ–∑–¥–∞–Ω–æ {len(all_words)} –∑–∞–ø–∏—Å–µ–π")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print_stats(all_words)

    # –ü—Ä–∏–º–µ—Ä—ã
    print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã (–ø–µ—Ä–≤—ã–µ 10):")
    for i, word in enumerate(all_words[:10], 1):
        print(f"  {word['id']:4d}. {word['en']:15} [{word['level']}]")

    print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5):")
    for word in all_words[-5:]:
        print(f"  {word['id']:4d}. {word['en']:15} [{word['level']}]")


if __name__ == "__main__":
    main()